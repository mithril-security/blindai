{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1d3af6",
   "metadata": {},
   "source": [
    "# About this example\n",
    "\n",
    "This example shows how you can deploy COVID-Net model to analyze X-Ray scans of chest X-rays to detect COVID. \n",
    "\n",
    "By using BlindAI, people can send data for the AI to analyze their medical images without having to fear privacy leaks.\n",
    "\n",
    "COVID-Net is a deep CNN to detect COVID from chest X-rays. You can learn more about it on the [COVID-Net repository](https://github.com/lindawangg/COVID-Net).\n",
    "\n",
    "More information on this use case can be found on our blog post [Confidential medical image analysis with COVID-Net and BlindAI](https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334419ad",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46efa7c9",
   "metadata": {},
   "source": [
    "Install the dependencies this example needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow numpy opencv-python onnxruntime matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3766101f",
   "metadata": {},
   "source": [
    "Install the latest version of BlindAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blindai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa298c",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698eef5",
   "metadata": {},
   "source": [
    "For this example, we will directly download a Covid-NET model that has already been trained. The model is already in ONNX file so no need to export it.\n",
    "\n",
    "Because the file is rather big, the download might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65576d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Rzl_XpV_kBw-lzu_5xYpc8briFd7fjvc' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Rzl_XpV_kBw-lzu_5xYpc8briFd7fjvc\" -O COVID-Net-CXR-2.onnx && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919ccb5",
   "metadata": {},
   "source": [
    "# Deployment on BlindAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e7e48",
   "metadata": {},
   "source": [
    "Please make sure the **server is running**. To launch the server, refer to the [Launching the server](https://docs.mithrilsecurity.io/getting-started/quick-start/run-the-blindai-server) documentation page. \n",
    "\n",
    "If you have followed the steps and have the Docker image ready, this mean you simply have to run `docker run -it -p 50051:50051 -p 50052:50052 mithrilsecuritysas/blindai-server-sim:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79537d6",
   "metadata": {},
   "source": [
    "So the first thing we need to do is to connect securely to the BlindAI server instance. Here we will use simulation mode for ease of use. This means that we do not leverage the hardware security propertiers of secure enclaves, but we do not need to run the Docker image with a specific hardware.\n",
    "\n",
    "If you wish to run this example in hardware mode, you need to prepare the `host_server.pem` and `policy.toml` files. Learn more on the [Deploy on Hardware](https://docs.mithrilsecurity.io/getting-started/deploy-on-hardware) documentation page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ddc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blindai.client import BlindAiClient, ModelDatumType\n",
    "\n",
    "# Launch client\n",
    "client = BlindAiClient()\n",
    "\n",
    "# Simulation mode\n",
    "client.connect_server(addr=\"localhost\", simulation=True)\n",
    "\n",
    "# Hardware mode\n",
    "# client.connect_server(addr=\"localhost\", policy=\"./policy.toml\", certificate=\"./host_server.pem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d5725",
   "metadata": {},
   "source": [
    "Then, upload the model inside the BlindAI server. This simply means uploading the ONNX file created before.\n",
    "\n",
    "When uploading the model, we have to precise the shape of the input and the data type. \n",
    "\n",
    "In this case, because we use a CNN model, we simply need to send floats of the image normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebcddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.upload_model(model=\"./COVID-Net-CXR-2.onnx\", shape=(1,480,480,3), dtype=ModelDatumType.F32)\n",
    "model_id = response.model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5c14e",
   "metadata": {},
   "source": [
    "# Sending data for  confidential prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d1531",
   "metadata": {},
   "source": [
    "Now it's time to check it's working live!\n",
    "\n",
    "We will just prepare some input for the model inside the secure enclave of BlindAI to process it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac0a3b",
   "metadata": {},
   "source": [
    "First, we need to fetch the CXR image to send to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/lindawangg/COVID-Net/master/assets/ex-covid.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835b1ccd",
   "metadata": {},
   "source": [
    "We will use the same preprocessing functions as in the [COVID-Net repository](https://github.com/lindawangg/COVID-Net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20396b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses OpenCV for image processing\n",
    "import cv2\n",
    "\n",
    "def crop_top(img, percent=0.15):\n",
    "    offset = int(img.shape[0] * percent)\n",
    "    return img[offset:]\n",
    "\n",
    "def central_crop(img):\n",
    "    size = min(img.shape[0], img.shape[1])\n",
    "    offset_h = int((img.shape[0] - size) / 2)\n",
    "    offset_w = int((img.shape[1] - size) / 2)\n",
    "    return img[offset_h:offset_h + size, offset_w:offset_w + size]\n",
    "\n",
    "def process_image_file(filepath, size, top_percent=0.08, crop=True):\n",
    "    img = cv2.imread(filepath)\n",
    "    img = crop_top(img, percent=top_percent)\n",
    "    if crop:\n",
    "        img = central_crop(img)\n",
    "    img = cv2.resize(img, (size, size))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5605148",
   "metadata": {},
   "source": [
    "We can now load the image we have downloaded and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = process_image_file(\"./ex-covid.jpeg\", size=480)\n",
    "img = img.astype(\"float32\") / 255.0\n",
    "img = img[np.newaxis,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0948aba",
   "metadata": {},
   "source": [
    "We can have a look at the model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d94c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744fcc9",
   "metadata": {},
   "source": [
    "For data marshalling reason, we will flatten the image and convert it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_img = img.flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4866369",
   "metadata": {},
   "source": [
    "We can then send the data to be processed by the BlindAI server!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.run_model(model_id, flattened_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf49edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0])\n",
    "plt.title(f\"Probability of COVID positivity: {response.output[1]}\")\n",
    "\n",
    "print(response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e609cfb",
   "metadata": {},
   "source": [
    "Here we can compare the results against the original prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"COVID-Net-CXR-2.onnx\")\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: img}\n",
    "\n",
    "onnx_outputs = ort_session.run(None, ort_inputs)\n",
    "print(f\"Probability of COVID positivity from original model: {onnx_outputs[0][0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f9721",
   "metadata": {},
   "source": [
    "Et voila! We have been able to apply a start of the art model of image recognition, without ever having to show the data in clear to the people operating the service!\n",
    "\n",
    "If you have liked this example, do not hesitate to drop a star on our [GitHub](https://github.com/mithril-security/blindai) and chat with us on our [Discord](https://discord.gg/TxEHagpWd4)!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5388ad2301bd502d89111dcdf0be4de1267e42deee031a75c954f6a954bbfcf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
