{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithril-security/blindai/blob/jupyter-0.5.0/examples/covidnet/BlindAI-COVID-Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1d3af6",
      "metadata": {
        "id": "6f1d3af6"
      },
      "source": [
        "# About this example\n",
        "\n",
        "This example shows how you can deploy COVID-Net model to analyze X-Ray scans of chest X-rays to detect COVID. \n",
        "\n",
        "By using BlindAI, people can send data for the AI to analyze their medical images without having to fear privacy leaks.\n",
        "\n",
        "COVID-Net is a deep CNN to detect COVID from chest X-rays. You can learn more about it on the [COVID-Net repository](https://github.com/lindawangg/COVID-Net).\n",
        "\n",
        "More information on this use case can be found on our blog post [Confidential medical image analysis with COVID-Net and BlindAI](https://blog.mithrilsecurity.io/confidential-covidnet-with-blindai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "334419ad",
      "metadata": {
        "id": "334419ad"
      },
      "source": [
        "# Installing dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46efa7c9",
      "metadata": {
        "id": "46efa7c9"
      },
      "source": [
        "Install the dependencies this example needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6625af10",
      "metadata": {
        "id": "6625af10",
        "outputId": "116e8e8f-8c1e-4a63-ca14-a1d15ee5049b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.12.1-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (21.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pillow numpy opencv-python onnxruntime matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3766101f",
      "metadata": {
        "id": "3766101f"
      },
      "source": [
        "Install the latest version of BlindAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4bc9033d",
      "metadata": {
        "id": "4bc9033d",
        "outputId": "fd1130d4-2888-47e4-d4b9-186954e9f50c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting blindai\n",
            "  Downloading blindai-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting grpcio-tools>=1.4\n",
            "  Downloading grpcio_tools-1.48.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 53.0 MB/s \n",
            "\u001b[?25hCollecting bitstring\n",
            "  Downloading bitstring-3.1.9-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from blindai) (4.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from blindai) (0.10.2)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.4 in /usr/local/lib/python3.7/dist-packages (from blindai) (1.47.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.4->blindai) (1.15.0)\n",
            "Collecting grpcio>=1.4\n",
            "  Downloading grpcio-1.48.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from grpcio-tools>=1.4->blindai) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from grpcio-tools>=1.4->blindai) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->blindai) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->blindai) (2.21)\n",
            "Installing collected packages: grpcio, grpcio-tools, cryptography, bitstring, blindai\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.47.0\n",
            "    Uninstalling grpcio-1.47.0:\n",
            "      Successfully uninstalled grpcio-1.47.0\n",
            "Successfully installed bitstring-3.1.9 blindai-0.5.0 cryptography-38.0.1 grpcio-1.48.1 grpcio-tools-1.48.1\n"
          ]
        }
      ],
      "source": [
        "!pip install blindai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efa298c",
      "metadata": {
        "id": "2efa298c"
      },
      "source": [
        "# Preparing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9698eef5",
      "metadata": {
        "id": "9698eef5"
      },
      "source": [
        "For this example, we will directly download a Covid-NET model that has already been trained. We have pre-exported the model from the [COVID-Net repository](https://github.com/lindawangg/COVID-Net) in ONNX file so no need to export it.\n",
        "\n",
        "Because the file is rather big, the download might take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "65576d34",
      "metadata": {
        "id": "65576d34"
      },
      "outputs": [],
      "source": [
        "!wget --quiet --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Rzl_XpV_kBw-lzu_5xYpc8briFd7fjvc' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1Rzl_XpV_kBw-lzu_5xYpc8briFd7fjvc\" -O COVID-Net-CXR-2.onnx && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8919ccb5",
      "metadata": {
        "id": "8919ccb5"
      },
      "source": [
        "# Deployment on BlindAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "963e7e48",
      "metadata": {
        "id": "963e7e48"
      },
      "source": [
        "Please make sure the **server is running**. To launch the server, refer to the [Launching the server](https://docs.mithrilsecurity.io/getting-started/quick-start/run-the-blindai-server) documentation page. \n",
        "\n",
        "If you have followed the steps and have the Docker image ready, this mean you simply have to run `docker run -it -p 50051:50051 -p 50052:50052 mithrilsecuritysas/blindai-server-sim:latest`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79537d6",
      "metadata": {
        "id": "b79537d6"
      },
      "source": [
        "So the first thing we need to do is to connect securely to the BlindAI server instance. Here we will use simulation mode for ease of use. This means that we do not leverage the hardware security propertiers of secure enclaves, but we do not need to run the Docker image with a specific hardware.\n",
        "\n",
        "If you wish to run this example in hardware mode, you need to prepare the `host_server.pem` and `policy.toml` files. Learn more on the [Deploy on Hardware](https://docs.mithrilsecurity.io/getting-started/deploy-on-hardware) documentation page. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155ddc68",
      "metadata": {
        "id": "155ddc68"
      },
      "outputs": [],
      "source": [
        "import blindai.client\n",
        "from blindai.client import ModelDatumType\n",
        "\n",
        "# Launch client in simulation mode\n",
        "client = blindai.client.connect(addr=\"localhost\", simulation=True)\n",
        "\n",
        "# Launch client in hardware mode\n",
        "# client = blindai.client.connect(addr=\"localhost\", policy=\"./policy.toml\", certificate=\"./host_server.pem\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889d5725",
      "metadata": {
        "id": "889d5725"
      },
      "source": [
        "Then, upload the model inside the BlindAI server. This simply means uploading the ONNX file created before.\n",
        "\n",
        "When uploading the model, we have to precise the shape of the input and the data type. \n",
        "\n",
        "In this case, because we use a CNN model, we simply need to send floats of the image normalized between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ebcddf6",
      "metadata": {
        "id": "7ebcddf6"
      },
      "outputs": [],
      "source": [
        "response = client.upload_model(model=\"./COVID-Net-CXR-2.onnx\", shape=(1,480,480,3), dtype=ModelDatumType.F32)\n",
        "model_id = response.model_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df5c14e",
      "metadata": {
        "id": "3df5c14e"
      },
      "source": [
        "# Sending data for  confidential prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb7d1531",
      "metadata": {
        "id": "cb7d1531"
      },
      "source": [
        "Now it's time to check it's working live!\n",
        "\n",
        "We will just prepare some input for the model inside the secure enclave of BlindAI to process it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dac0a3b",
      "metadata": {
        "id": "8dac0a3b"
      },
      "source": [
        "First, we need to fetch the CXR image to send to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccde18dd",
      "metadata": {
        "id": "ccde18dd"
      },
      "outputs": [],
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/lindawangg/COVID-Net/master/assets/ex-covid.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "835b1ccd",
      "metadata": {
        "id": "835b1ccd"
      },
      "source": [
        "We will use the same preprocessing functions as in the [COVID-Net repository](https://github.com/lindawangg/COVID-Net)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20396b6f",
      "metadata": {
        "id": "20396b6f"
      },
      "outputs": [],
      "source": [
        "# This uses OpenCV for image processing\n",
        "import cv2\n",
        "\n",
        "def crop_top(img, percent=0.15):\n",
        "    offset = int(img.shape[0] * percent)\n",
        "    return img[offset:]\n",
        "\n",
        "def central_crop(img):\n",
        "    size = min(img.shape[0], img.shape[1])\n",
        "    offset_h = int((img.shape[0] - size) / 2)\n",
        "    offset_w = int((img.shape[1] - size) / 2)\n",
        "    return img[offset_h:offset_h + size, offset_w:offset_w + size]\n",
        "\n",
        "def process_image_file(filepath, size, top_percent=0.08, crop=True):\n",
        "    img = cv2.imread(filepath)\n",
        "    img = crop_top(img, percent=top_percent)\n",
        "    if crop:\n",
        "        img = central_crop(img)\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5605148",
      "metadata": {
        "id": "f5605148"
      },
      "source": [
        "We can now load the image we have downloaded and preprocess it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1cb2e83",
      "metadata": {
        "id": "f1cb2e83"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "img = process_image_file(\"./ex-covid.jpeg\", size=480)\n",
        "img = img.astype(\"float32\") / 255.0\n",
        "img = img[np.newaxis,:,:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0948aba",
      "metadata": {
        "id": "d0948aba"
      },
      "source": [
        "We can have a look at the model input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d94c0a",
      "metadata": {
        "id": "51d94c0a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a744fcc9",
      "metadata": {
        "id": "a744fcc9"
      },
      "source": [
        "For data marshalling reason, we will flatten the image and convert it to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b5abd6",
      "metadata": {
        "id": "d0b5abd6"
      },
      "outputs": [],
      "source": [
        "flattened_img = img.flatten().tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4866369",
      "metadata": {
        "id": "d4866369"
      },
      "source": [
        "We can then send the data to be processed by the BlindAI server!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac8b4612",
      "metadata": {
        "id": "ac8b4612"
      },
      "outputs": [],
      "source": [
        "response = client.run_model(model_id, flattened_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf49edd",
      "metadata": {
        "id": "1bf49edd"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img[0])\n",
        "plt.title(f\"Probability of COVID positivity: {response.output[1]}\")\n",
        "\n",
        "print(response.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e609cfb",
      "metadata": {
        "id": "9e609cfb"
      },
      "source": [
        "Here we can compare the results against the original prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c06fc11",
      "metadata": {
        "id": "5c06fc11"
      },
      "outputs": [],
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"COVID-Net-CXR-2.onnx\")\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: img}\n",
        "\n",
        "onnx_outputs = ort_session.run(None, ort_inputs)\n",
        "print(f\"Probability of COVID positivity from original model: {onnx_outputs[0][0][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d74f9721",
      "metadata": {
        "id": "d74f9721"
      },
      "source": [
        "Et voila! We have been able to apply a start of the art model of image recognition, without ever having to show the data in clear to the people operating the service!\n",
        "\n",
        "If you have liked this example, do not hesitate to drop a star on our [GitHub](https://github.com/mithril-security/blindai) and chat with us on our [Discord](https://discord.gg/TxEHagpWd4)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63f56f88",
      "metadata": {
        "id": "63f56f88"
      },
      "outputs": [],
      "source": [
        "client.delete_model(model_id)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "d4728e1a3ff73eb9f349d79cccba999964e06e0723f28c97cabf0434506e63b1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}