{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mithril-security/blindai/blob/master/examples/resnet18/BlindAI_ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of BlindAI deployment with ResNet18\n",
    "\n",
    "We will see in this notebook how to deploy and query a ResNet18 model on BlindAI Cloud. To upload of the model, make sure you have an API key.\n",
    "\n",
    "You can get one on the [Mithril Cloud](https://cloud.mithrilsecurity.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's install `blindai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blindai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the model to BlindAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to get the model in ONNX format. Let's pull the ResNet18 model from PyTorch Hub and export in in ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# We need to provide an example of input with the right shape to export\n",
    "dummy_inputs = torch.zeros(1,3,224,224)\n",
    "torch.onnx.export(model, dummy_inputs, \"resnet18.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can upload the model to BlindAI Cloud. To upload of the model, make sure you have an API key.\n",
    "\n",
    "You can get one on the [Mithril Cloud](https://cloud.mithrilsecurity.io/).\n",
    "\n",
    "You might get an error if the name you want to use is already taken, as models are uniquely identified by their `model_id`. We will implement namespace soon to avoid that. Meanwhile, you will have to choose a unique ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blindai\n",
    "\n",
    "api_key = \"YOUR_API_KEY\" # Enter your API key here\n",
    "\n",
    "# Upload the ONNX file along with specs and model name\n",
    "with blindai.Connection(api_key=api_key) as client:\n",
    "    response = client.upload_model(\"resnet18.onnx\", model_id=\"resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is uploaded, we just need to feed it with data. Let's first grab the image we want the model to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "# Download an example image from the pytorch website\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "# sample execution (requires torchvision)\n",
    "input_image = Image.open(filename)\n",
    "input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess the image to make it usable by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to connect to the model inside the secure enclave and query it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blindai\n",
    "import torch\n",
    "\n",
    "with blindai.Connection(api_key=api_key) as client:\n",
    "  # Send data to the ResNet18 model\n",
    "  prediction = client.predict(\"ec3d2f13-0830-4459-a67a-f9db5e32b014\", input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the name of the prediction now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://git.io/JJkYN\")\n",
    "labels = response.text.split(\"\\n\")\n",
    "\n",
    "output = prediction.output[0].as_torch()\n",
    "probabilities = torch.nn.functional.softmax(output)\n",
    "\n",
    "labels[probabilities.argmax().item()], probabilities.max().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have liked this example, do not hesitate to drop a star on our [GitHub](https://github.com/mithril-security/blindai) and chat with us on our [Discord](https://discord.gg/TxEHagpWd4)!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
