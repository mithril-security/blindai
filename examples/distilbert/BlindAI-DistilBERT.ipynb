{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9f250e",
   "metadata": {},
   "source": [
    "# About this example\n",
    "\n",
    "This example shows how you can run the DistilBERT model. You can learn more about it on this [Hugging Face page](https://huggingface.co/docs/transformers/model_doc/distilbert).\n",
    "\n",
    "The model will be left untrained for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334419ad",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9cfaa",
   "metadata": {},
   "source": [
    "Install the dependencies this example needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6625af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers[onnx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008593de",
   "metadata": {},
   "source": [
    "Install the latest version of BlindAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc9033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet blindai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553770d3",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cac160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "# Load the model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abe440",
   "metadata": {},
   "source": [
    "Then, export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6fcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "# Create dummy input for export\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "sentence = \"I love AI and privacy!\"\n",
    "inputs = tokenizer(sentence, padding = \"max_length\", max_length = 8, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "\tmodel, inputs, \"./distilbert-base-uncased.onnx\",\n",
    "\texport_params=True, opset_version=11,\n",
    "\tinput_names = ['input'], output_names = ['output'],\n",
    "\tdynamic_axes={'input' : {0 : 'batch_size'},\n",
    "\t'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58d76d",
   "metadata": {},
   "source": [
    "This may take a little while."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8d46a",
   "metadata": {},
   "source": [
    "# Upload model to inference server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670d7eb",
   "metadata": {},
   "source": [
    "Please make sure the server is running. To launch the server, refer to the [Launching the server](https://docs.mithrilsecurity.io/getting-started/quick-start/run-the-blindai-server) documentation page.\n",
    "\n",
    "If you wish to run this example in hardware mode, you need to prepare the `host_server.pem` and `policy.toml` files. Learn more on the [Deploy on Hardware](https://docs.mithrilsecurity.io/getting-started/deploy-on-hardware) documentation page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155ddc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Untrusted server certificate check bypassed\n",
      "WARNING:root:Attestation process is bypassed: running without requesting and checking attestation\n"
     ]
    }
   ],
   "source": [
    "from blindai.client import BlindAiClient, ModelDatumType\n",
    "\n",
    "# Launch client\n",
    "client = BlindAiClient()\n",
    "\n",
    "# Simulation mode\n",
    "client.connect_server(addr=\"localhost\", simulation=True)\n",
    "# Hardware mode\n",
    "# client.connect_server(addr=\"localhost\", policy=\"./policy.toml\", certificate=\"./host_server.pem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d5725",
   "metadata": {},
   "source": [
    "Then, upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a8b79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<blindai.client.UploadModelResponse at 0x7fcba144a8d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upload_model(model=\"./distilbert-base-uncased.onnx\", shape=inputs.shape, dtype=ModelDatumType.I64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5c14e",
   "metadata": {},
   "source": [
    "# Send data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b6f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Prepare the inputs\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "sentence = \"I love AI and privacy!\"\n",
    "inputs = tokenizer(sentence, padding = \"max_length\", max_length = 8)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8b4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1299879103899002, 0.016796546056866646]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.run_model(inputs)\n",
    "response.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e609cfb",
   "metadata": {},
   "source": [
    "Here we can compare the results against the original prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c06fc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1300, 0.0168]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(inputs).unsqueeze(0)).logits.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
